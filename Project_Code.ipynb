{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "36f86fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import nltk.translate.bleu_score as bleu\n",
    "import tensorflow as tf\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from  tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "aeb2d72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And he took in my favorite subject like soccer .</td>\n",
       "      <td>And he took in my favorite subjects like socce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actually , who let me know about Lang - 8 was ...</td>\n",
       "      <td>Actually , he was the one who let me know abou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>His Kanji 's ability is much better than me .</td>\n",
       "      <td>His Kanji ability is much better than mine .\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We 've known each other for only half a year ,...</td>\n",
       "      <td>We 've known each other for only half a year ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I heard a sentence last night when I watched TV .</td>\n",
       "      <td>I heard a sentence last night when I was watch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511158</th>\n",
       "      <td>Hmmm... Thk i usually book on wkends... Depend...</td>\n",
       "      <td>Hmm. I think I usually book on weekends. It de...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511159</th>\n",
       "      <td>ask them got any sms messages to gif me lei......</td>\n",
       "      <td>Can you ask them whether they have for any sms...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511160</th>\n",
       "      <td>We r near coca oredi...\\n</td>\n",
       "      <td>We are near Coca already.\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511161</th>\n",
       "      <td>hall Eleven. Got lectures le mah.èn forget abt...</td>\n",
       "      <td>Hall eleven. Got lectures. And forget about co...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511162</th>\n",
       "      <td>I Bring for u. I can not promise u 100% to win...</td>\n",
       "      <td>I bring for you. I can not promise you 100% to...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input  \\\n",
       "0        And he took in my favorite subject like soccer .   \n",
       "1       Actually , who let me know about Lang - 8 was ...   \n",
       "2           His Kanji 's ability is much better than me .   \n",
       "3       We 've known each other for only half a year ,...   \n",
       "4       I heard a sentence last night when I watched TV .   \n",
       "...                                                   ...   \n",
       "511158  Hmmm... Thk i usually book on wkends... Depend...   \n",
       "511159  ask them got any sms messages to gif me lei......   \n",
       "511160                          We r near coca oredi...\\n   \n",
       "511161  hall Eleven. Got lectures le mah.èn forget abt...   \n",
       "511162  I Bring for u. I can not promise u 100% to win...   \n",
       "\n",
       "                                                   output  y  \n",
       "0       And he took in my favorite subjects like socce...  1  \n",
       "1       Actually , he was the one who let me know abou...  1  \n",
       "2          His Kanji ability is much better than mine .\\n  1  \n",
       "3       We 've known each other for only half a year ,...  1  \n",
       "4       I heard a sentence last night when I was watch...  1  \n",
       "...                                                   ... ..  \n",
       "511158  Hmm. I think I usually book on weekends. It de...  2  \n",
       "511159  Can you ask them whether they have for any sms...  2  \n",
       "511160                        We are near Coca already.\\n  2  \n",
       "511161  Hall eleven. Got lectures. And forget about co...  2  \n",
       "511162  I bring for you. I can not promise you 100% to...  2  \n",
       "\n",
       "[511163 rows x 3 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LOADING THE PROCESSED DATASET\n",
    "df= pd.read_csv(\"data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "33d5fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(text):\n",
    "    text = re.sub(r\" '(\\w)\",r\"'\\1\",text)\n",
    "    text = re.sub(r\" \\,\",\",\",text)\n",
    "    text = re.sub(r\" \\.+\",\".\",text)\n",
    "    text = re.sub(r\" \\!+\",\"!\",text)\n",
    "    text = re.sub(r\" \\?+\",\"?\",text)\n",
    "    text = re.sub(\" n't\",\"n't\",text)\n",
    "    text = re.sub(\"[\\(\\)\\;\\_\\^\\`\\/]\",\"\",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8e746308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontract(text):\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    return text\n",
    "def clear_result(value):\n",
    "    if value > 0.1:\n",
    "        return value\n",
    "    else:\n",
    "        return 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "5f108934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(\"\\n\",\"\",text)\n",
    "    text = remove_spaces(text)   # REMOVING UNWANTED SPACES\n",
    "    text = re.sub(r\"\\.+\",\".\",text)\n",
    "    text = re.sub(r\"\\!+\",\"!\",text)\n",
    "    text = decontract(text)    # DECONTRACTION\n",
    "    text = re.sub(\"[^A-Za-z0-9 ]+\",\"\",text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e749f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"processed_input\"] = df.input.apply(preprocess) \n",
    "df[\"processed_output\"] = df.output.apply(preprocess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a8c0b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.drop([\"input\",\"output\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "541b7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "573e6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"processed_input\",\"processed_output\",\"y\"]].to_csv(\"My_processed_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "97973275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"My_processed_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "859f5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"enc_input\",\"dec_input\",\"y\"] \n",
    "df[\"dec_output\"] = df.dec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "47aebd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dec_input\"]= \"<start> \" + df[\"dec_input\"]\n",
    "df[\"dec_output\"] =  df[\"dec_output\"] + \" <end>\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256cb8d",
   "metadata": {},
   "source": [
    "### all data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "59b64928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train ,test_data = train_test_split(df,test_size=0.4,random_state = 3, stratify = df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7090e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>467725</th>\n",
       "      <td>1</td>\n",
       "      <td>i study esl in the morning</td>\n",
       "      <td>&lt;start&gt; i study eslin the morning &lt;end&gt;</td>\n",
       "      <td>i study eslin the morning &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157998</th>\n",
       "      <td>1</td>\n",
       "      <td>there are lots of  fake  antiques in the market</td>\n",
       "      <td>&lt;start&gt; there are lots of fake antiques on the...</td>\n",
       "      <td>there are lots of fake antiques on the market ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92568</th>\n",
       "      <td>1</td>\n",
       "      <td>for example the terms  herbivorous boys  was i...</td>\n",
       "      <td>&lt;start&gt; for example the term  herbivorous boys...</td>\n",
       "      <td>for example the term  herbivorous boys  was in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63596</th>\n",
       "      <td>1</td>\n",
       "      <td>now i am going to say about my dream</td>\n",
       "      <td>&lt;start&gt; now i am going to talk about my dream</td>\n",
       "      <td>now i am going to talk about my dream &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137183</th>\n",
       "      <td>1</td>\n",
       "      <td>but i do not use iphone in sex until now</td>\n",
       "      <td>&lt;start&gt; but i have never used iphone for sex</td>\n",
       "      <td>but i have never used iphone for sex &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171848</th>\n",
       "      <td>1</td>\n",
       "      <td>he appealed for the world peace</td>\n",
       "      <td>&lt;start&gt; he appealed for world peace</td>\n",
       "      <td>he appealed for world peace &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458048</th>\n",
       "      <td>1</td>\n",
       "      <td>it  s a good phenomenon to the ordinary people...</td>\n",
       "      <td>&lt;start&gt; it  s a good phenomenon for ordinary p...</td>\n",
       "      <td>it  s a good phenomenon for ordinary people li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130664</th>\n",
       "      <td>1</td>\n",
       "      <td>i begin to learn english on today</td>\n",
       "      <td>&lt;start&gt; i am beginning to learn english today</td>\n",
       "      <td>i am beginning to learn english today &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372999</th>\n",
       "      <td>1</td>\n",
       "      <td>i am interesting in manga japan animation and ...</td>\n",
       "      <td>&lt;start&gt; i am interested in manga japanese anim...</td>\n",
       "      <td>i am interested in manga japanese animation an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67752</th>\n",
       "      <td>1</td>\n",
       "      <td>in either event his speech was amazing</td>\n",
       "      <td>&lt;start&gt; either way his speech was always amazing</td>\n",
       "      <td>either way his speech was always amazing &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303538 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y                                          enc_input  \\\n",
       "467725  1                         i study esl in the morning   \n",
       "157998  1    there are lots of  fake  antiques in the market   \n",
       "92568   1  for example the terms  herbivorous boys  was i...   \n",
       "63596   1               now i am going to say about my dream   \n",
       "137183  1           but i do not use iphone in sex until now   \n",
       "...    ..                                                ...   \n",
       "171848  1                    he appealed for the world peace   \n",
       "458048  1  it  s a good phenomenon to the ordinary people...   \n",
       "130664  1                  i begin to learn english on today   \n",
       "372999  1  i am interesting in manga japan animation and ...   \n",
       "67752   1             in either event his speech was amazing   \n",
       "\n",
       "                                                dec_input  \\\n",
       "467725            <start> i study eslin the morning <end>   \n",
       "157998  <start> there are lots of fake antiques on the...   \n",
       "92568   <start> for example the term  herbivorous boys...   \n",
       "63596       <start> now i am going to talk about my dream   \n",
       "137183       <start> but i have never used iphone for sex   \n",
       "...                                                   ...   \n",
       "171848                <start> he appealed for world peace   \n",
       "458048  <start> it  s a good phenomenon for ordinary p...   \n",
       "130664      <start> i am beginning to learn english today   \n",
       "372999  <start> i am interested in manga japanese anim...   \n",
       "67752    <start> either way his speech was always amazing   \n",
       "\n",
       "                                               dec_output  \n",
       "467725                    i study eslin the morning <end>  \n",
       "157998  there are lots of fake antiques on the market ...  \n",
       "92568   for example the term  herbivorous boys  was in...  \n",
       "63596         now i am going to talk about my dream <end>  \n",
       "137183         but i have never used iphone for sex <end>  \n",
       "...                                                   ...  \n",
       "171848                  he appealed for world peace <end>  \n",
       "458048  it  s a good phenomenon for ordinary people li...  \n",
       "130664        i am beginning to learn english today <end>  \n",
       "372999  i am interested in manga japanese animation an...  \n",
       "67752      either way his speech was always amazing <end>  \n",
       "\n",
       "[303538 rows x 4 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train[\"dec_input\"].iloc[0]  = df_train.iloc[0][\"dec_input\"] + \" <end>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "571d7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val,df_test = train_test_split(test_data,test_size=0.5,random_state = 3, stratify = test_data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafdd15c",
   "metadata": {},
   "source": [
    "### part of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "5d33b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = pd.concat((df[df.y==1].sample(frac= 0.2,random_state=1),df[df.y==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "de137124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train ,df_val = train_test_split(df_sampled,test_size=0.2,random_state = 3, stratify = df_sampled.y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "a32f55e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "df_train[\"dec_input\"].iloc[0]  = df_train.iloc[0][\"dec_input\"] + \" <end>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9854fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5) \n",
    "df_test = df.loc[np.random.choice(np.array([x for x in df.index.values if x not in df_sampled.index.values]),1000,replace= False,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "28676eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tk_inp = Tokenizer()\n",
    "tk_inp.fit_on_texts(df_train.enc_input.apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "033c1a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_out = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n' )\n",
    "tk_out.fit_on_texts(df_train.dec_input.apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f2a1433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inp = df_train[\"enc_input\"].apply(str).values\n",
    "decoder_inp = df_train[\"dec_input\"].apply(str).values\n",
    "decoder_out = df_train[\"dec_output\"].apply(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "6f75f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(j,max_len):\n",
    "    encoder_seq = tk_inp.texts_to_sequences([encoder_inp[j]])\n",
    "    decoder_inp_seq = tk_out.texts_to_sequences([decoder_inp[j]])\n",
    "    decoder_out_seq = tk_out.texts_to_sequences([decoder_out[j]])\n",
    "        \n",
    "    encoder_seq = pad_sequences(encoder_seq, padding=\"post\",maxlen = max_len)\n",
    "    decoder_inp_seq = pad_sequences(decoder_inp_seq, padding=\"post\",maxlen = max_len)\n",
    "    decoder_out_seq = pad_sequences(decoder_out_seq ,padding=\"post\", maxlen = max_len)\n",
    "    \n",
    "    return encoder_seq ,  decoder_inp_seq,  decoder_out_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "2427b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessAllData(tf.keras.utils.Sequence):\n",
    "    def __init__(self,batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.samples_count = encoder_inp.shape[0]\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i+1)*self.batch_size\n",
    "        \n",
    "        encoder_batches =[]\n",
    "        decoder_input_batches = []\n",
    "        decoder_output_batches =[]\n",
    "        \n",
    "        for j in range(start,stop): \n",
    "            a,b,c = process_sample(j,35)\n",
    "            encoder_batches.append(a[0]) \n",
    "            decoder_input_batches.append(b[0])\n",
    "            decoder_output_batches.append(c[0])\n",
    "        encoder_batches = (np.array(encoder_batches)) \n",
    "        decoder_input_batches = np.array(decoder_input_batches)\n",
    "        decoder_output_batches = np.array(decoder_output_batches)\n",
    "        \n",
    "        return [encoder_batches , decoder_input_batches],decoder_output_batches\n",
    "    def __len__(self):\n",
    "        return int(self.samples_count/self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "28af575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_batches = ProcessAllData(batch_size = 512)\n",
    "val_data_batches = ProcessAllData(batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f1a66",
   "metadata": {},
   "source": [
    "### Encoder Implementaion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d54c23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = layers.Embedding(input_dim= len(tk_inp.word_index)+1,\n",
    "                                         output_dim = 300,\n",
    "                                         mask_zero = True,\n",
    "                                          input_length = 35\n",
    "                                         )\n",
    "lstm=layers.Bidirectional(layers.LSTM(units= 256,return_state = True,return_sequences=True ))\n",
    "\n",
    "encoder_input = layers.Input(shape=(35))\n",
    "\n",
    "concat1 = layers.Concatenate()\n",
    "concat2 = layers.Concatenate()\n",
    "\n",
    "embedd=embedding(encoder_input)\n",
    "\n",
    "output , state_h1 , state_c1 ,state_h2 , state_c2 = lstm(embedd)\n",
    "state_h = concat1([state_h1,state_h2])\n",
    "state_c  = concat2(([state_c1,state_c2]))\n",
    "encoder_state = [state_h,state_c] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b47c38f",
   "metadata": {},
   "source": [
    "### Decoder Implementaion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d52f1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding2 = layers.Embedding(input_dim = len(tk_out.word_index)+1,\n",
    "                                          output_dim = 300,\n",
    "                                         mask_zero=True,\n",
    "                                         input_length = 35)\n",
    "lstm2 = layers.LSTM(units = 512,\n",
    "                    return_sequences=True,\n",
    "                    return_state=True)\n",
    "decoder_input=layers.Input(shape = (35))\n",
    "embedd2=embedding(decoder_input)\n",
    "\n",
    "output2,state_h,state_c = lstm2(embedd2,initial_state = encoder_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35062543",
   "metadata": {},
   "source": [
    "#### Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2e80789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = layers.Dense(len(tk_out.word_index)+1,activation=\"softmax\")(output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04865354",
   "metadata": {},
   "source": [
    "### Building The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "2b9208ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = Model(inputs=[encoder_input,decoder_input],outputs=dense)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "9ba91b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback =[ tf.keras.callbacks.ModelCheckpoint( \"My_Model/besh.h5\",save_best_only=True,mode=\"min\" ,save_weights_only=True),\n",
    "           tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,verbose=1,min_delta=0.0001),\n",
    "            tf.keras.callbacks.TensorBoard(\"My_Model/logs/save\",histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "3204977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = len(train_data_batches)\n",
    "validation_steps  = len(val_data_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "18be5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f3117468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           [(None, 35)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_25 (InputLayer)           [(None, 35)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 35, 300)      10013400    input_25[0][0]                   \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional [(None, 35, 512), (N 1140736     embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 512)          0           bidirectional_12[0][1]           \n",
      "                                                                 bidirectional_12[0][3]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 512)          0           bidirectional_12[0][2]           \n",
      "                                                                 bidirectional_12[0][4]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                  [(None, 35, 512), (N 1665024     embedding_18[1][0]               \n",
      "                                                                 concatenate_24[0][0]             \n",
      "                                                                 concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 35, 27306)    14007978    lstm_19[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,827,138\n",
      "Trainable params: 26,827,138\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "416e5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Encoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "47e327f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Decoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "e758e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Model_Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303681b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  2/592 [..............................] - ETA: 4:37:51 - loss: 4.0105 "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_batches,\n",
    "                    steps_per_epoch=train_steps,\n",
    "                    epochs=50,\n",
    "                    validation_data = val_data_batches,\n",
    "                    validation_steps =validation_steps,\n",
    "                    callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "4dbf9967",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"My_Best_Weights/besh.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "434d0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the internet\n",
    "def predict(ita_text,model):\n",
    "    \n",
    "    seq = tk_inp.texts_to_sequences([ita_text])\n",
    "\n",
    "    seq = pad_sequences(seq,maxlen = 20 , padding=\"post\")\n",
    "    \n",
    "    enc_output,state_h,state_c= model.layers[2](seq)\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    input_state = [state_h,state_c]\n",
    "    current_vec = tf.ones((1,1))\n",
    "    \n",
    "    for i in range(20):\n",
    "        dec_output,dec_state_h,dec_state_c = model.layers[3](current_vec , input_state)\n",
    "\n",
    "        dense = model.layers[4](dec_output)\n",
    "\n",
    "        current_vec = np.argmax(dense ,axis = -1)\n",
    "\n",
    "        input_state = [dec_state_h,dec_state_c]\n",
    "\n",
    "        pred.append(tk_out.index_word[current_vec[0][0]])\n",
    "        \n",
    "        if tk_out.index_word[current_vec[0][0]]==\"<end>\":\n",
    "            break\n",
    "        \n",
    "    return \" \".join(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be30f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c8a3a2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Moaed\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "3it [00:00,  6.27it/s]C:\\Users\\Moaed\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Moaed\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "2000it [05:20,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BELU =  0.4549907036917097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BLEU = []\n",
    "np.random.seed(1)\n",
    "test_data = df_val.loc[np.random.choice(df_val.index,size =2000 ,replace=False)]\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        pred = predict(str(i.enc_input),model).split()\n",
    "        act = [str(i.dec_output).split()]\n",
    "        b = bleu.sentence_bleu(act,pred)\n",
    "        b=clear_result(b)\n",
    "        BLEU.append(b)\n",
    "    except:\n",
    "      continue\n",
    "print(\"BELU = \", np.mean(BLEU))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191d819",
   "metadata": {},
   "source": [
    "### Using Beam_Search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1cbeceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement from the internet\n",
    "def beam_search(input,model,k):\n",
    "    seq = tk_inp.texts_to_sequences([input])\n",
    "    seq = pad_sequences(seq,maxlen = 35,padding=\"post\")\n",
    "\n",
    "    \n",
    "    enc_gru ,enc_state_h,enc_state_c   = model.layers[2](seq)\n",
    "\n",
    "    input_state = [enc_state_h,enc_state_c ]\n",
    "    \n",
    "    k_beams = [[tf.ones((1,1),dtype=tf.int32),0.0]]\n",
    "    for i in range(35):\n",
    "        candidates = []\n",
    "        for sent_pred , prob in k_beams :\n",
    "            if tk_out.word_index[\"<end>\"] in sent_pred.numpy() :\n",
    "\n",
    "                candidates += [[sent_pred , prob]]\n",
    "            else:\n",
    "                \n",
    "                dec_gru , dec_state_h ,dec_state_c = model.layers[3](sent_pred , input_state)\n",
    "                dense = model.layers[4](tf.expand_dims(dec_state_h,axis=0))\n",
    "                pred = tf.argsort(dense, direction= 'DESCENDING')[:,:,:k]\n",
    "                for w in range(k):\n",
    "                  candidates += [[tf.concat((sent_pred, pred[:,:,w]) , axis=-1) , (prob + tf.math.log(dense[:,:,pred[:,:,w][0][0]])[0][0])]  ]\n",
    "        k_beams = sorted(candidates,key=lambda tup:tup[1],reverse=True)[:k]\n",
    "\n",
    "    all_sent = []\n",
    "    for i,score in k_beams:\n",
    "        sent = \"\"\n",
    "        for j in range(1,35):\n",
    "            sent +=  tk_out.index_word[i.numpy()[:,j][0]] +  \" \" \n",
    "            if tk_out.index_word[i.numpy()[:,j][0]] ==\"<end>\":\n",
    "                break\n",
    "        all_sent.append((sent.strip(),score.numpy()))\n",
    "    return all_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "606dadaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [34:05,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BELU Beam Search Score =  0.4578538023600538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION BELU SCORE\n",
    "BLEU_beam = []\n",
    "np.random.seed(1)\n",
    "test_data = df_val.loc[np.random.choice(df_val.index,size = 2000,replace=False)]\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        pred = beam_search(str(i.enc_input),model,3)[0][0].split()\n",
    "        act = [str(i.dec_output).split()]\n",
    "        b =bleu.sentence_bleu(act,pred)\n",
    "        b=clear_result(b)\n",
    "        BLEU_beam.append(b)\n",
    "    except:\n",
    "          continue\n",
    "\n",
    "print(\"BELU Beam Search Score = \",np.mean(BLEU_beam))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5936e04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi i have friends <end>\n"
     ]
    }
   ],
   "source": [
    "test1=\"hi i are friends\"\n",
    "print(predict(test1,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f71dfd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a nice place <end>\n"
     ]
    }
   ],
   "source": [
    "test2=\"tihs is a nice place\"\n",
    "print(predict(test2,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "91a2a9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am in a house <end>\n"
     ]
    }
   ],
   "source": [
    "test3 = \"i am in house\"\n",
    "print(predict(test3,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ab65b628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this dog has a beautiful face <end>\n"
     ]
    }
   ],
   "source": [
    "test4='this dog have beautiful face'\n",
    "print(predict(test4,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d863ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you <end>\n"
     ]
    }
   ],
   "source": [
    "test5= 'hwo are you'\n",
    "print(predict(test5,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "5a4d325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you good <end>\n"
     ]
    }
   ],
   "source": [
    "test6 = 'is you good'\n",
    "print(predict(test6,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "2bb2d6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is you ok <end>\n"
     ]
    }
   ],
   "source": [
    "test7 = 'is you ok'\n",
    "print(predict(test7,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbe9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
